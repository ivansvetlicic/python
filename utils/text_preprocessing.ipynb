{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pobEfvMzhL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "01777ea4-3450-4365-d74f-ad54db1e0777"
      },
      "source": [
        "import re, string, unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from multiprocessing import Pool, cpu_count\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "cachedStopWords = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXWO-t1d0Lc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define helper functions for text prep/cleanup\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile(r'[(){}\\/[\\]:\\&|@,;-]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^a-z ]')\n",
        "\n",
        "ls = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFaG1K_K0u5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regex(text):\n",
        "  text = re.sub('#', 'number', text)\n",
        "  text = re.sub('%', 'percent', text)\n",
        "  text = re.sub('w/', 'with', text)\n",
        "  text = re.sub('w/o', 'without', text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FeyrETI1Scc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_invalid_chars(text):\n",
        "  text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQLvlP-h1bpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_bad_symbold(text):\n",
        "  text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HtWV1rJ1mTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWT54Nvatd8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  return ' '.join([word for word in text.split() if word not in cachedStopWords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe14UOPD10Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_process_text(text):\n",
        "  processed_text = ''\n",
        "  text = remove_stopwords(text)\n",
        "  for word in word_tokenize(text):\n",
        "    #if word in stopwords.words('english'):\n",
        "    #  continue\n",
        "    modified_word = lemmatizer.lemmatize(word)\n",
        "\n",
        "    if modified_word == '.':\n",
        "      #don't add space if period\n",
        "      processed_text += modified_word\n",
        "    elif processed_text != '':\n",
        "      processed_text += ' ' + modified_word.casefold()\n",
        "    else:\n",
        "      processed_text = modified_word.casefold()\n",
        "  return processed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN5ProQw2_XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming (text):\n",
        "  processed_text = ''\n",
        "\n",
        "  for word in word_tokenize(text):\n",
        "    modified_word = ls.stem (word)\n",
        "\n",
        "    if modified_word == '.':\n",
        "      #don't add space if period\n",
        "      processed_text += modified_word\n",
        "    elif processed_text != '':\n",
        "      processed_text += ' ' + modified_word.casefold()\n",
        "    else:\n",
        "      processed_text = modified_word.casefold()\n",
        "  return processed_text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_qmgJx_3h1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def strip_html(text):\n",
        "  soup = BeautifulSoup(text, \"html_parser\")\n",
        "  return soup.get_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUPRFyHT5Htn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_between_square_brackets(text):\n",
        "  return re.sub('\\[[^}}*\\]', '', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfOlMisc5Yc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_blanks(text):\n",
        "  processed_text = ''\n",
        "  for word in word_tokenize(text):\n",
        "    if word != '':\n",
        "      if processed_text != '':\n",
        "        #don't add extra space before a period\n",
        "        if word == '.':\n",
        "          processed_text += word\n",
        "        else:\n",
        "          processed_text += ' ' + word\n",
        "      else:\n",
        "        processed_text = word\n",
        "  return processed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F_ByPxl6GDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_prep(text, params=[nltk_process_text, regex, remove_blanks], display_progress=True):\n",
        "  if (display_progress):\n",
        "    for param in params:\n",
        "      print(\"applying:\", param.__name__)\n",
        "      text = text.progress_apply(param)\n",
        "  else:\n",
        "    for param in params:\n",
        "      text = text.apply(param)\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq65sVTo6hfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sample usage\n",
        "#import pandas as pd\n",
        "#text_str = \"This text needs to be processed. Please do it for me.\"\n",
        "#sample_text = [text_str]\n",
        "#sample_df = pd.DataFrame(data = sample_text, columns = ['text'])\n",
        "\n",
        "#preprocessed_text = text_prep(sample_df['text'])\n",
        "\n",
        "#print(\"Original text:\", text_str)\n",
        "#print(\"Preprocessed text:\", preprocessed_text[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlo1MxOOuB2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}